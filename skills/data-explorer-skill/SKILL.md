---
name: data-explorer
description: æ•°æ®å±‚æ¢ç´¢ä¸“å®¶ã€‚æŸ¥è¯¢æ•°æ®ã€ç†è§£ç»“æ„ã€ä¼˜åŒ–æ€§èƒ½æ—¶ä½¿ç”¨ã€‚å¤ç”¨ç°æœ‰æ–¹æ³•ï¼Œé¿å…é‡å¤é€ è½®å­ã€‚åªè¦è·Ÿæ•°æ®æœåŠ¡æ¢ç´¢ç›¸å…³çš„éƒ½ä¼˜å…ˆä½¿ç”¨è¿™ä¸ª skills
tags:
  - data
  - database
  - explore
  - query
  - data-layer
---

# æ•°æ®æ¢ç´¢ä¸“å®¶

æ¢ç´¢é¡¹ç›®æ•°æ®å±‚ï¼Œå‘ç°å¹¶å¤ç”¨ç°æœ‰æŸ¥è¯¢æ–¹æ³•ï¼ŒæŒ‰è§„èŒƒæ„å»ºæ–°ä»£ç ã€‚**å¤ç”¨ > æ–°å»ºï¼Œå¯æ‰§è¡Œ > çº¸ä¸Šè°ˆå…µ**ã€‚

## æ¢ç´¢æ€ç»´

åœ¨å†™ä»£ç ä¹‹å‰ï¼Œå…ˆå›ç­”è¿™äº›é—®é¢˜ï¼š

- **ä¸šåŠ¡ç›®æ ‡**: è¿™ä¸ªæ•°æ®ç”¨æ¥å¹²ä»€ä¹ˆï¼Ÿè°åœ¨ç”¨ï¼Ÿé¢‘ç‡å¦‚ä½•ï¼Ÿ
- **æ•°æ®å®šä½**: å­˜åœ¨å“ªä¸ªåº“ï¼Ÿä»€ä¹ˆç±»å‹ï¼Ÿè§„æ¨¡å¤šå¤§ï¼Ÿ
- **ç°æœ‰èµ„äº§**: é¡¹ç›®é‡Œæœ‰æ²¡æœ‰ç°æˆçš„æŸ¥è¯¢æ–¹æ³•ï¼Ÿèƒ½ä¸èƒ½å¤ç”¨ï¼Ÿ
- **æ€§èƒ½çº¦æŸ**: å®æ—¶æŸ¥è¯¢ï¼ˆ<100msï¼‰è¿˜æ˜¯ç¦»çº¿åˆ†æï¼ˆåˆ†é’Ÿçº§ï¼‰ï¼Ÿ
- **å®‰å…¨è¾¹ç•Œ**: éœ€è¦ä»€ä¹ˆæƒé™ï¼Ÿæ•°æ®æ˜¯å¦æ•æ„Ÿï¼Ÿ

**CRITICAL**: æ°¸è¿œå…ˆæœç´¢é¡¹ç›®ç°æœ‰çš„æŸ¥è¯¢æ–¹æ³•ã€‚å¤ç”¨ä¸€ä¸ªæˆç†Ÿçš„ Repository æ–¹æ³•ï¼Œæ¯”ä»é›¶å†™ä¸€ä¸ª"æ›´ä¼˜é›…"çš„æŸ¥è¯¢æ›´æœ‰ä»·å€¼ã€‚ä»£ç å¤ç”¨ > ä»£ç ä¼˜é›…ã€‚

ç„¶åç”Ÿæˆå¯ç›´æ¥æ‰§è¡Œçš„ä»£ç ï¼Œè¦æ±‚ï¼š
- ä¼˜å…ˆè°ƒç”¨é¡¹ç›®ç°æœ‰çš„ Repository/Service/DAO æ–¹æ³•
- æ–°å»ºæ–¹æ³•å¿…é¡»ç¬¦åˆé¡¹ç›®å‘½åè§„èŒƒå’Œç›®å½•ç»“æ„
- è€ƒè™‘ç´¢å¼•ã€åˆ†é¡µã€ç¼“å­˜ç­‰æ€§èƒ½å› ç´ 
- å‚æ•°åŒ–æŸ¥è¯¢ï¼Œé˜²æ­¢æ³¨å…¥

**CRITICAL**: æ°¸è¿œå…ˆæœç´¢é¡¹ç›®ç°æœ‰æŸ¥è¯¢æ–¹æ³•ã€‚å¤ç”¨æˆç†Ÿçš„ Repository æ–¹æ³• > ä»é›¶å†™"æ›´ä¼˜é›…"çš„æŸ¥è¯¢ã€‚

## èƒ½åŠ›èŒƒå›´

- **æ•°æ®åº“**: PostgreSQL, MySQL, MongoDB, Elasticsearch, Redis, Milvus, Neo4j, InfluxDB
- **ä¼˜åŒ–**: ç´¢å¼•ç­–ç•¥ã€æ‰§è¡Œè®¡åˆ’ã€N+1è¯Šæ–­ã€åˆ†é¡µã€ç¼“å­˜
- **ORM**: SQLAlchemy, Prisma, TypeORM, Sequelize, Django ORM, Mongoose

## æ¢ç´¢æµç¨‹

### å®Œæ•´çš„æ•°æ®æ¢ç´¢ Baselineï¼ˆ7æ­¥å·¥ç¨‹æ–¹æ³•ï¼‰

è¿™ä¸ªæµç¨‹æ˜¯ä»å®æˆ˜ç»éªŒä¸­æ€»ç»“å‡ºæ¥çš„ç«¯åˆ°ç«¯æ–¹æ³•ï¼Œé€‚ç”¨äºæ‰€æœ‰æ•°æ®å±‚è®¾è®¡ã€‚

```
ã€è¾“å…¥ã€‘ä¸šåŠ¡éœ€æ±‚ â†’ ã€è¾“å‡ºã€‘å¯æŠ•äº§çš„æ•°æ®æ£€ç´¢æ–¹æ¡ˆ + æ€§èƒ½æŠ¥å‘Š
```

#### ç¬¬ 1 æ­¥ï¼šæ´å¯Ÿä¸šåŠ¡éœ€æ±‚ï¼ˆéœ€æ±‚åˆ†è§£ï¼‰

**ç›®æ ‡**: æ˜ç¡®è¿™ä¸ªæ•°æ®æŸ¥è¯¢çš„çœŸå®åœºæ™¯å’Œçº¦æŸ

```
é—®è‡ªå·±:
â–¡ ç”¨æˆ·æ˜¯è°ï¼Ÿä»€ä¹ˆåœºæ™¯ä¸‹ä½¿ç”¨è¿™ä¸ªæ•°æ®ï¼Ÿ
â–¡ å®æ—¶å“åº”è¦æ±‚æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆç§’çº§/åˆ†é’Ÿçº§/å°æ—¶çº§ï¼‰
â–¡ æ•°æ®é‡è§„æ¨¡å¤šå¤§ï¼Ÿï¼ˆåƒ/ä¸‡/ç™¾ä¸‡/äº¿çº§ï¼‰
â–¡ æŸ¥è¯¢é¢‘ç‡å¦‚ä½•ï¼Ÿï¼ˆç¨€ç–/å¸¸é¢‘/é«˜é¢‘ï¼‰
â–¡ èƒ½å¦ç¼“å­˜ï¼Ÿå¦‚æœèƒ½ï¼Œç¼“å­˜å¤šä¹…ï¼ˆçƒ­åº¦åˆ†æï¼‰ï¼Ÿ
â–¡ æ˜¯å¦æ¶‰åŠå¤šä¸ªæ•°æ®æºï¼Ÿå¦‚æœæ˜¯ï¼Œæ•°æ®æ˜¯å¦åŒæ­¥ï¼Ÿ
```

**è¾“å‡º**: éœ€æ±‚æ¸…å• + çº¦æŸè¯´æ˜

**å®æˆ˜æ¡ˆä¾‹**:
```
éœ€æ±‚: è·å–æ–°é—»è¯¦æƒ…ï¼ŒåŒ…æ‹¬åŸå§‹ HTML
åœºæ™¯: ç¼–è¾‘å®¡æ ¸å†…å®¹æ—¶è°ƒç”¨
å®æ—¶æ€§: <500msï¼ˆäººç±»æ„ŸçŸ¥é˜ˆå€¼ï¼‰
æ•°æ®é‡: ä¸‡çº§æ–°é—»
æŸ¥è¯¢é¢‘ç‡: ä¸­ç­‰ï¼ˆç¼–è¾‘æ‰‹åŠ¨æŸ¥è¯¢ï¼‰
ç¼“å­˜: å¯ç¼“å­˜ 1 å°æ—¶ï¼ˆæ–°é—»å‘å¸ƒåä¸å¸¸å˜åŒ–ï¼‰
å¤šæº: æ˜¯ï¼ŒMySQL(æƒå¨) + MongoDB(åŸå§‹HTML)
åŒæ­¥: æœªç¡®è®¤ï¼Œéœ€è¦éªŒè¯
```

---

### ç¬¬ 2 æ­¥ï¼šå¯è¡Œæ€§åˆ†æï¼ˆæ•°æ®è°ƒç ”ï¼‰

**ç›®æ ‡**: ç¡®ä¿éœ€æ±‚çš„æ•°æ®åœ¨ç³»ç»Ÿä¸­çœŸçš„å­˜åœ¨ä¸”å¯è®¿é—®

**CRITICAL**: è¿™ä¸€æ­¥å†³å®šäº†åç»­ 5 æ­¥æ˜¯å¦èƒ½æˆåŠŸã€‚è·³è¿‡è¿™æ­¥ä¼šå¯¼è‡´è¿”å·¥ã€‚

```
å¯è¡Œæ€§æ£€æŸ¥æ¸…å•:
â–¡ å­—æ®µæ˜¯å¦å­˜åœ¨ï¼Ÿï¼ˆå®é™…æœ‰è¿˜æ˜¯å‡è®¾æœ‰ï¼Ÿï¼‰
â–¡ å­—æ®µæ˜¯å¦æœ‰ç´¢å¼•ï¼Ÿï¼ˆæŸ¥è¯¢ä¼šå…¨è¡¨æ‰«æå—ï¼Ÿï¼‰
â–¡ å¦‚ä½•æŸ¥è¯¢è¿™ä¸ªå­—æ®µï¼Ÿï¼ˆç›´æ¥æŸ¥ vs JOIN vs Aggregationï¼‰
â–¡ æ•°æ®åˆ†å¸ƒæ˜¯å¦æ­£å¸¸ï¼Ÿï¼ˆæœ‰æ•ˆæ•°æ®å æ¯”ã€NULL ç‡ï¼‰
â–¡ è·¨æ•°æ®æºåœºæ™¯ï¼šæ•°æ®æ˜¯å¦æœ‰äº¤é›†ï¼Ÿï¼ˆåŒ¹é…ç‡å¤šå°‘ï¼Ÿï¼‰
â–¡ æ€§èƒ½åŸºçº¿ï¼šå•æ¬¡æŸ¥è¯¢å¤šä¹…ï¼Ÿï¼ˆæ— ä¼˜åŒ–çŠ¶æ€ï¼‰
```

**å®æˆ˜å­æ­¥éª¤**:

```python
# æ­¥éª¤ 2.1: å­—æ®µæ£€æŸ¥
def check_field_existence():
    """éªŒè¯å­—æ®µæ˜¯å¦çœŸçš„å­˜åœ¨"""
    doc = mongodb.find_one()
    if "html_content" not in doc:
        raise FieldMissingError("html_content å­—æ®µä¸å­˜åœ¨ï¼Œå®é™…å­—æ®µ: " + list(doc.keys()))

# æ­¥éª¤ 2.2: ç´¢å¼•æ£€æŸ¥
def check_indexes():
    """æ£€æŸ¥æŸ¥è¯¢å­—æ®µæ˜¯å¦æœ‰ç´¢å¼•"""
    indexes = mongodb.index_information()  # æˆ– mysql.SHOW INDEX FROM table
    if "url_md5" not in str(indexes):
        print("âš ï¸ url_md5 æ²¡æœ‰ç´¢å¼•ï¼Œå…¨è¡¨æ‰«æä¼šå¾ˆæ…¢")
        return False
    return True

# æ­¥éª¤ 2.3: æ•°æ®åˆ†å¸ƒæ£€æŸ¥
def analyze_data_distribution():
    """åˆ†ææ•°æ®è´¨é‡å’Œåˆ†å¸ƒ"""
    total = collection.count_documents({})
    valid = collection.count_documents({"html_content": {"$exists": True, "$ne": None}})
    null_rate = (total - valid) / total if total > 0 else 0

    print(f"æ€»æ–‡æ¡£æ•°: {total}")
    print(f"æœ‰æ•ˆæ•°æ®: {valid} ({(valid/total)*100:.1f}%)")
    print(f"NULL ç‡: {null_rate*100:.1f}%")

    if null_rate > 0.3:
        print("âš ï¸ NULL ç‡è¿‡é«˜ï¼Œéœ€è¦å¤„ç†é»˜è®¤å€¼é€»è¾‘")

# æ­¥éª¤ 2.4: è·¨æºåŒ¹é…åº¦æ£€æŸ¥ï¼ˆå¿…åšï¼‰
def validate_cross_source_match():
    """æ£€æŸ¥ MySQL çš„æ•°æ®åœ¨ MongoDB ä¸­çš„åŒ¹é…ç‡"""
    mysql_ids = execute_mysql("SELECT DISTINCT md5_url FROM nanshan_news_label LIMIT 1000")
    mongo_matches = mongodb.find({"url_md5": {"$in": mysql_ids}})
    match_rate = len(mongo_matches) / len(mysql_ids)

    if match_rate < 0.3:
        raise DataMismatchError(f"åŒ¹é…ç‡ä»… {match_rate:.1%}ï¼Œä¸å¯ç»§ç»­")

    return mongo_matches[:5]  # è¿”å›æµ‹è¯•ç”¨ ID

# æ­¥éª¤ 2.5: æ€§èƒ½åŸºçº¿ï¼ˆæ— ä»»ä½•ä¼˜åŒ–ï¼‰
def measure_baseline_performance():
    """å•æ¬¡æŸ¥è¯¢çš„åŸå§‹æ€§èƒ½"""
    import time
    test_ids = ["xxx", "yyy", "zzz"]  # ä»æ­¥éª¤ 2.4 è·å¾—

    times = []
    for test_id in test_ids:
        start = time.time()
        result = mongodb.find_one({"url_md5": test_id})
        times.append(time.time() - start)

    avg_time = sum(times) / len(times)
    print(f"å•æ¬¡æŸ¥è¯¢è€—æ—¶: {avg_time*1000:.2f}ms")

    # åˆ¤æ–­æ˜¯å¦éœ€è¦ä¼˜åŒ–
    if avg_time > 0.1:  # 100ms
        print("âš ï¸ æ€§èƒ½åŸºçº¿è¶…è¿‡ 100msï¼Œéœ€è¦ä¼˜åŒ–")
```

**è¾“å‡º**: å¯è¡Œæ€§æŠ¥å‘Š + å¯ç”¨æµ‹è¯•æ•°æ® + æ€§èƒ½åŸºçº¿æ•°æ®

---

### ç¬¬ 3 æ­¥ï¼šæ„å»ºæµ‹è¯•æ ·ä¾‹ï¼ˆæ•°æ®å›ºå®šåŒ–ï¼‰

**ç›®æ ‡**: æœ‰ä¸€å¥—å¯å¤ç°çš„æµ‹è¯•æ•°æ®ï¼Œè´¯ç©¿æ•´ä¸ªå¼€å‘ â†’ æµ‹è¯• â†’ æ€§èƒ½è¯„ä¼°æµç¨‹

```python
class TestDataRegistry:
    """æµ‹è¯•æ•°æ®æ³¨å†Œè¡¨ - ç¡®ä¿æ•´ä¸ªæµç¨‹ç”¨çš„æ˜¯åŒä¸€æ‰¹æ•°æ®"""

    # å¿…é¡»æ¥è‡ªæ­¥éª¤ 2.4 çš„å¯è¡Œæ€§åˆ†æ
    TEST_IDS = [
        "dc0a8cdd8d4ac05f7a7443ab62816ae0",  # MySQL + MongoDB éƒ½æœ‰
        "fd782ef7db31731a8e3d11b4d8d2e96f",  # ä¸¤è¾¹éƒ½æœ‰
        "ba1967bf0393af71dc410c68c2e3450f",  # ä¸¤è¾¹éƒ½æœ‰
    ]

    # æœŸæœ›ç»“æœï¼ˆä»æ­¥éª¤ 2 ä¸­è·å–çš„çœŸå®æ•°æ®ï¼‰
    EXPECTED_RESULTS = {
        "dc0a8cdd8d4ac05f7a7443ab62816ae0": {
            "title": "2025æ¸…å\"ç§‘åˆ›æ¯\"åˆ›ä¸šå¤§èµ›...",
            "html_content_length": 45000,  # æˆ–è€… Noneï¼ˆå¦‚æœ MongoDB æ²¡æœ‰ï¼‰
            "content": "å¤„ç†åçš„æ–‡æœ¬å†…å®¹...",
        },
        # ... æ›´å¤šæµ‹è¯•ç”¨ä¾‹
    }

    @staticmethod
    def validate_test_setup():
        """ç¡®ä¿æµ‹è¯•æ•°æ®æœ‰æ•ˆ"""
        for test_id in TestDataRegistry.TEST_IDS:
            # éªŒè¯è¿™ä¸ª ID åœ¨ MySQL ä¸­å­˜åœ¨
            mysql_result = query_mysql(f"SELECT * FROM nanshan_news_label WHERE md5_url = '{test_id}'")
            assert mysql_result is not None, f"æµ‹è¯• ID {test_id} åœ¨ MySQL ä¸­ä¸å­˜åœ¨"

            # éªŒè¯è¿™ä¸ª ID åœ¨ MongoDB ä¸­å­˜åœ¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
            mongo_result = query_mongo({"url_md5": test_id})
            assert mongo_result is not None, f"æµ‹è¯• ID {test_id} åœ¨ MongoDB ä¸­ä¸å­˜åœ¨"
```

**è¾“å‡º**: å›ºå®šçš„æµ‹è¯•æ•°æ®é›† + æœŸæœ›ç»“æœ

---

### ç¬¬ 4 æ­¥ï¼šæ„å»ºé«˜æ€§èƒ½æ£€ç´¢æ–¹æ¡ˆï¼ˆæ¶æ„è®¾è®¡ï¼‰

**ç›®æ ‡**: è®¾è®¡ä¸€ä¸ªæ»¡è¶³æ€§èƒ½çº¦æŸã€é¿å…å½±å“ä¸šåŠ¡çš„æŸ¥è¯¢æ–¹æ¡ˆ

```
æ€§èƒ½æ–¹æ¡ˆè®¾è®¡æ¸…å•:
â–¡ æ•°æ®åº“é€‰æ‹©ï¼šPostgreSQL/MySQL/MongoDB å“ªä¸ªä½œä¸ºä¸»æŸ¥è¯¢æºï¼Ÿ
â–¡ ç´¢å¼•ç­–ç•¥ï¼šéœ€è¦æ–°å»ºå“ªäº›ç´¢å¼•ï¼Ÿå¤åˆç´¢å¼•å¦‚ä½•è®¾è®¡ï¼Ÿ
â–¡ åˆ†é¡µç­–ç•¥ï¼šç”¨ limit/offset è¿˜æ˜¯ cursorï¼Ÿ
â–¡ ç¼“å­˜ç­–ç•¥ï¼šRedis/å†…å­˜ ç¼“å­˜å¤šå°‘æ•°æ®ï¼ŸTTL å¤šä¹…ï¼Ÿ
â–¡ å¼‚æ­¥å¤„ç†ï¼šéœ€è¦ MQ å¼‚æ­¥åŒ–å—ï¼Ÿè¿˜æ˜¯åŒæ­¥æŸ¥è¯¢è¶³å¤Ÿï¼Ÿ
â–¡ ç†”æ–­é™åˆ¶ï¼šå•æ¬¡æŸ¥è¯¢æœ€å¤§æ–‡æ¡£æ•°/å“åº”å¤§å°ï¼Ÿ
â–¡ ç›‘æ§å‘Šè­¦ï¼šå“ªäº›æŒ‡æ ‡éœ€è¦å‘Šè­¦ï¼Ÿé˜ˆå€¼å¤šå°‘ï¼Ÿ
```

**å®æˆ˜æ¡ˆä¾‹**:

```python
class NewsDetailQueryPlan:
    """æ–°é—»è¯¦æƒ…æŸ¥è¯¢æ–¹æ¡ˆ"""

    # æ€§èƒ½çº¦æŸ
    SLA_RESPONSE_TIME = 500  # ms
    MAX_FETCH_SIZE = 5 * 1024 * 1024  # 5MB
    MAX_TIMEOUT = 3000  # ms

    async def get_news_detail(self, md5_url: str):
        """
        é«˜æ€§èƒ½æ£€ç´¢æ–¹æ¡ˆï¼š
        1. å…ˆæŸ¥ Redis ç¼“å­˜ (TTL: 1å°æ—¶)
        2. ç¼“å­˜æœªå‘½ä¸­ â†’ æŸ¥ MySQL ä¸»è¡¨
        3. MySQL æ‰¾åˆ° â†’ å¼‚æ­¥è¡¥å…… MongoDB åŸå§‹ HTML
        4. æ„é€ å“åº”ï¼Œè¿”å›

        æ€§èƒ½ç›®æ ‡: <500ms (P95)
        """

        # æ­¥éª¤ 1: ç¼“å­˜æ£€æŸ¥ï¼ˆå¿«è·¯å¾„ï¼‰
        cache_key = f"news:detail:{md5_url}"
        cached = await redis.get(cache_key)
        if cached:
            return json.loads(cached)  # ç¼“å­˜å‘½ä¸­ï¼Œç›´æ¥è¿”å›

        # æ­¥éª¤ 2: MySQL æŸ¥è¯¢ï¼ˆä¸»è·¯å¾„ï¼‰
        mysql_result = await mysql.query(
            "SELECT * FROM nanshan_news_label WHERE md5_url = %s",
            (md5_url,),
            timeout=100  # 100ms è¶…æ—¶
        )

        if not mysql_result:
            raise HTTPException(status_code=404)

        result = dict(mysql_result)

        # æ­¥éª¤ 3: MongoDB å¼‚æ­¥è¡¥å……ï¼ˆéå…³é”®è·¯å¾„ï¼‰
        mongo_html = await asyncio.wait_for(
            self._get_mongo_html(md5_url),
            timeout=200  # 200ms è¶…æ—¶ï¼Œè¶…æ—¶ä¹Ÿä¸å½±å“è¿”å›
        )

        if mongo_html:
            result["html_content"] = mongo_html
            result["content_source"] = "raw_html"
        else:
            result["content_source"] = "database"

        # æ­¥éª¤ 4: ç¼“å­˜ç»“æœ
        await redis.setex(
            cache_key,
            3600,  # 1 å°æ—¶è¿‡æœŸ
            json.dumps(result)
        )

        return result

    async def _get_mongo_html(self, md5_url: str):
        """ä» MongoDB è·å–åŸå§‹ HTMLï¼Œè¶…æ—¶æ—¶ä¸æŠ¥é”™"""
        try:
            doc = await mongodb.find_one({"url_md5": md5_url})
            return doc.get("html_content") if doc else None
        except Exception as e:
            logger.warning(f"MongoDB æŸ¥è¯¢å¤±è´¥: {e}")
            return None  # é™çº§å¤„ç†
```

**è¾“å‡º**: å®Œæ•´çš„æŸ¥è¯¢æ¶æ„è®¾è®¡ + æ€§èƒ½ç›®æ ‡

---

### ç¬¬ 5 æ­¥ï¼šå®ç°æŸ¥è¯¢å‡½æ•° + æµ‹è¯•éªŒè¯ï¼ˆç¼–ç  + è°ƒè¯•ï¼‰

**ç›®æ ‡**: ç”¨ç¬¬ 3 æ­¥çš„æµ‹è¯•æ•°æ®éªŒè¯å®ç°çš„æ­£ç¡®æ€§

```python
async def test_news_detail_retrieval():
    """ç”¨æµ‹è¯•æ•°æ®è¿›è¡Œå®Œæ•´éªŒè¯"""

    for test_id in TestDataRegistry.TEST_IDS:
        # æ‰§è¡ŒæŸ¥è¯¢
        result = await news_service.get_news_detail(test_id)

        # éªŒè¯è¿”å›æ•°æ®
        assert result is not None, f"ID {test_id} è¿”å›ä¸ºç©º"
        assert result["md5_url"] == test_id, "è¿”å›æ•°æ®ä¸åŒ¹é…"
        assert result["title"], "æ ‡é¢˜ç¼ºå¤±"
        assert "content_source" in result, "content_source å­—æ®µç¼ºå¤±"

        # éªŒè¯ä¸šåŠ¡é€»è¾‘
        if result["content_source"] == "raw_html":
            assert result.get("html_content"), "html_content åº”è¯¥æœ‰å€¼"
            assert len(result["html_content"]) > 100, "html_content å¤ªçŸ­"

        print(f"âœ… æµ‹è¯•ç”¨ä¾‹ {test_id} é€šè¿‡")

    print("âœ… æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹é€šè¿‡")
```

**è¾“å‡º**: é€šè¿‡æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹çš„å¯ç”¨ä»£ç 

---

### ç¬¬ 6 æ­¥ï¼šæ•ˆç‡è¯„ä¼°ï¼ˆæ€§èƒ½æµ‹è¯•ï¼‰

**ç›®æ ‡**: åœ¨å®é™…çº¦æŸä¸‹è¯„ä¼°æŸ¥è¯¢æ€§èƒ½æ˜¯å¦è¾¾åˆ° SLA

```python
async def benchmark_query_performance():
    """å®Œæ•´çš„æ€§èƒ½è¯„ä¼°"""

    import statistics

    # é…ç½®
    WARMUP_RUNS = 10        # é¢„çƒ­
    BENCHMARK_RUNS = 100    # åŸºå‡†æµ‹è¯•
    CONCURRENT_USERS = 10   # å¹¶å‘æ¨¡æ‹Ÿ

    print("=" * 80)
    print("æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 80)

    # æ­¥éª¤ 1: ç¼“å­˜é¢„çƒ­
    print("\n[1/4] ç¼“å­˜é¢„çƒ­...")
    for test_id in TestDataRegistry.TEST_IDS * 5:
        await news_service.get_news_detail(test_id)

    # æ­¥éª¤ 2: å•çº¿ç¨‹æ€§èƒ½
    print("[2/4] å•çº¿ç¨‹æ€§èƒ½æµ‹è¯•...")
    response_times = []
    for test_id in TestDataRegistry.TEST_IDS * (BENCHMARK_RUNS // len(TestDataRegistry.TEST_IDS)):
        start = time.time()
        result = await news_service.get_news_detail(test_id)
        elapsed = (time.time() - start) * 1000  # è½¬ä¸º ms
        response_times.append(elapsed)

    # æ­¥éª¤ 3: ç»Ÿè®¡æŒ‡æ ‡
    print("[3/4] æ€§èƒ½ç»Ÿè®¡...")
    stats = {
        "count": len(response_times),
        "min": min(response_times),
        "max": max(response_times),
        "avg": statistics.mean(response_times),
        "median": statistics.median(response_times),
        "p95": sorted(response_times)[int(len(response_times) * 0.95)],
        "p99": sorted(response_times)[int(len(response_times) * 0.99)],
    }

    print("\næŸ¥è¯¢æ€§èƒ½æŒ‡æ ‡:")
    print(f"  æœ€å°: {stats['min']:.2f}ms")
    print(f"  å¹³å‡: {stats['avg']:.2f}ms")
    print(f"  ä¸­ä½: {stats['median']:.2f}ms")
    print(f"  P95:  {stats['p95']:.2f}ms")
    print(f"  P99:  {stats['p99']:.2f}ms")
    print(f"  æœ€å¤§: {stats['max']:.2f}ms")

    # æ­¥éª¤ 4: æ€§èƒ½è¯„ä¼°
    print("[4/4] æ€§èƒ½è¯„ä¼°...")
    SLA_TARGET = 500  # ms

    if stats["p95"] < SLA_TARGET:
        print(f"âœ… æ€§èƒ½è¾¾æ ‡: P95 {stats['p95']:.2f}ms < {SLA_TARGET}ms")
    else:
        print(f"âŒ æ€§èƒ½æœªè¾¾æ ‡: P95 {stats['p95']:.2f}ms > {SLA_TARGET}ms")
        print("   å»ºè®®: å¢åŠ ç¼“å­˜/æ·»åŠ ç´¢å¼•/æ•°æ®åˆ†ç‰‡")

    # æ­¥éª¤ 5: å¹¶å‘æµ‹è¯•
    print("\n[å¹¶å‘å‹åŠ›æµ‹è¯•]")
    async def concurrent_test():
        tasks = []
        for i in range(CONCURRENT_USERS * 10):
            test_id = TestDataRegistry.TEST_IDS[i % len(TestDataRegistry.TEST_IDS)]
            tasks.append(news_service.get_news_detail(test_id))

        start = time.time()
        results = await asyncio.gather(*tasks)
        elapsed = time.time() - start

        throughput = len(results) / elapsed
        print(f"  å¹¶å‘ç”¨æˆ·: {CONCURRENT_USERS}")
        print(f"  ååé‡: {throughput:.2f} req/s")
        print(f"  æ€»è€—æ—¶: {elapsed:.2f}s")

    await concurrent_test()

    return stats
```

**è¾“å‡º**: è¯¦ç»†çš„æ€§èƒ½æŠ¥å‘Š + ç“¶é¢ˆåˆ†æ

---

### ç¬¬ 7 æ­¥ï¼šç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šï¼ˆäº¤ä»˜æ–‡æ¡£ï¼‰

**ç›®æ ‡**: æ¸…æ™°åœ°è®°å½•æ•´ä¸ªæ–¹æ¡ˆï¼Œä¾¿äºåç»­ç»´æŠ¤å’Œå®¡è®¡

```markdown
# æ–°é—»è¯¦æƒ…æ•°æ®æ£€ç´¢æ–¹æ¡ˆæŠ¥å‘Š

## ğŸ“‹ èƒŒæ™¯è¯´æ˜

**ä¸šåŠ¡éœ€æ±‚**: ç¼–è¾‘åœ¨å®¡æ ¸é¡µé¢æŸ¥çœ‹æ–°é—»è¯¦æƒ…ï¼ŒåŒ…æ‹¬åŸå§‹ HTML
**å“åº”æ—¶é—´è¦æ±‚**: <500ms (P95)
**å¹´æŸ¥è¯¢é‡**: ~100ä¸‡æ¬¡ï¼ˆæœˆå‡ï¼‰

## ğŸ“Š æ¶‰åŠçš„æ•°æ®æº

| æ•°æ®æº | è¡¨/é›†åˆ | å­—æ®µ | ç”¨é€” | æ•°æ®é‡ |
|-------|--------|------|------|--------|
| MySQL | nanshan_ent_qxb.nanshan_news_label | md5_url, title, content | æƒå¨æ•°æ® | 50ä¸‡ |
| MongoDB | WaiQian_JingYing_FuChi.new_09_detail | url_md5, html_content | åŸå§‹ HTML | 87ä¸‡ |

**æ•°æ®åŒ¹é…åº¦**: 35ä¸‡æ¡ (70%)

## ğŸ—ï¸ ä»£ç æ¶æ„

```
src/
â”œâ”€â”€ domain/services/
â”‚   â””â”€â”€ news_detail_service.py      # ä¸šåŠ¡é€»è¾‘å±‚ï¼ˆç¼“å­˜+æŸ¥è¯¢ç»„åˆï¼‰
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â”œâ”€â”€ mysql_news_repo.py      # MySQL æŸ¥è¯¢
â”‚   â”‚   â””â”€â”€ mongo_html_repo.py      # MongoDB æŸ¥è¯¢
â”‚   â””â”€â”€ cache/
â”‚       â””â”€â”€ news_cache.py           # Redis ç¼“å­˜å±‚
â””â”€â”€ presentation/api/
    â””â”€â”€ endpoints/news.py           # API ç«¯ç‚¹
```

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡

**å•çº¿ç¨‹æ€§èƒ½** (100 æ¬¡æŸ¥è¯¢):
- å¹³å‡: 45ms
- P95: 120ms âœ… (è¾¾åˆ° SLA 500ms)
- P99: 280ms

**å¹¶å‘å‹åŠ›** (10 ç”¨æˆ· Ã— 10 è¯·æ±‚):
- ååé‡: 220 req/s
- æ— é”™è¯¯ç‡

**ç¼“å­˜æ•ˆæœ**:
- å‘½ä¸­ç‡: 75% (ç”Ÿäº§é¢„æœŸ)
- ç¼“å­˜åŠ é€Ÿ: 8-10x

## âš¡ ä¼˜åŒ–æªæ–½

1. **Redis ç¼“å­˜** - TTL 1å°æ—¶ï¼Œé¢„æœŸå‘½ä¸­ç‡ 75%
2. **å¤åˆç´¢å¼•** - MongoDB çš„ url_md5 + html_content
3. **å¼‚æ­¥è¡¥å……** - MongoDB æŸ¥è¯¢ä¸é˜»å¡ä¸»å“åº”
4. **ç†”æ–­é™åˆ¶** - 200ms è¶…æ—¶ï¼ŒMongoDB ä¸å¯ç”¨æ—¶é™çº§

## âœ… éªŒè¯æ¸…å•

- [x] MySQL æ•°æ®åº“å¯è®¿é—®
- [x] MongoDB æ•°æ®åº“å¯è®¿é—®
- [x] æ•°æ®åŒ¹é…ç‡è¾¾åˆ° 70%
- [x] æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹é€šè¿‡
- [x] æ€§èƒ½è¾¾åˆ° SLA
- [x] ç¼“å­˜ç­–ç•¥æœ‰æ•ˆ
- [x] å¼‚å¸¸å¤„ç†å®Œå–„

## ğŸš€ éƒ¨ç½²å»ºè®®

1. æå‰é¢„çƒ­ Redis ç¼“å­˜ï¼ˆå¯¼å…¥çƒ­æ•°æ®ï¼‰
2. ç›‘æ§ MongoDB è¿æ¥çŠ¶æ€ï¼ŒåŠæ—¶å‘Šè­¦
3. è®¾ç½® P95 å“åº”æ—¶é—´å‘Šè­¦é˜ˆå€¼ä¸º 300ms
4. å‘¨æœŸæ€§å›æºéªŒè¯ç¼“å­˜æ•°æ®æ–°é²œåº¦

---

ç”Ÿæˆæ—¶é—´: 2025-12-03
éªŒè¯è€…: AI Data Explorer
```

**è¾“å‡º**: å¯æŠ•äº§çš„å®Œæ•´æŠ¥å‘Š

---


### 0. è·¨æ•°æ®æºé›†æˆé¢„æ£€ï¼ˆå½“æ¶‰åŠå¤šä¸ªæ•°æ®æºæ—¶å¿…åšï¼‰âš ï¸

**CRITICAL**: å¤šæ•°æ®æºé›†æˆå®¹æ˜“å¯¼è‡´è¿”å·¥ï¼ŒåŠ¡å¿…åœ¨ç¼–ç å‰åšå®Œæ•´é¢„æ£€ã€‚

### ç¬¬ 1 å±‚ï¼šç†è§£ä¸šåŠ¡éœ€æ±‚

```
é—®è‡ªå·±:
â–¡ ç”¨æˆ·è¦è·å–ä»€ä¹ˆå­—æ®µ/æ•°æ®?
â–¡ è¿™äº›æ•°æ®ç”¨æ¥åšä»€ä¹ˆ?
â–¡ éœ€è¦ä»€ä¹ˆç»´åº¦çš„æ•°æ®èšåˆ?
â–¡ æ˜¯å¦æ¶‰åŠå¤šä¸ªæ•°æ®æº/è¡¨? â†’ å¦‚æœæ˜¯ï¼Œå…ˆåš"æ­¥éª¤ 0"é¢„æ£€
â–¡ å®æ—¶æ€§è¦æ±‚ vs è®¡ç®—æˆæœ¬?
```

**è¾“å‡º**: ä¸šåŠ¡éœ€æ±‚åˆ†è§£æ–‡æ¡£


### 2. æ¢ç´¢æ•°æ®æº
```bash
# æ‰¾é…ç½®
grep -r "DATABASE_URL\|DB_HOST\|MONGO_URI" . --include="*.env*" --include="*.yml" 2>/dev/null
# æ‰¾ schema
find . -name "*database*" -o -name "*schema*" -o -name "*migration*" | head -20
# è¯†åˆ«é©±åŠ¨
grep -E "postgres|mongodb|mysql|elasticsearch" package.json requirements.txt 2>/dev/null
```

### 3. å‘ç°ç°æœ‰æ–¹æ³•ï¼ˆæ ¸å¿ƒï¼‰
```bash
# æ‰¾ Repository/DAO/Service
find . -type f \( -name "*Repository*" -o -name "*Dao*" -o -name "*Service*" \) ! -path "*/node_modules/*" | head -20
# æ‰¾æŸ¥è¯¢æ–¹æ³•
grep -r "def get_\|def find_\|def list_" . --include="*.py" | head -20
grep -r "findOne\|findAll\|findBy" . --include="*.ts" --include="*.js" | head -20
```

**å†³ç­–**: æœ‰ç°æˆ â†’ ç›´æ¥ç”¨ | æœ‰ç±»ä¼¼ â†’ æ‰©å±•å‚æ•° | æ²¡æœ‰ â†’ æŒ‰è§„èŒƒæ–°å»º

### 4. è¯†åˆ«å­—æ®µç±»å‹ï¼ˆå¢åˆ æ”¹æŸ¥å‰å¿…åšï¼‰

**CRITICAL**: åœ¨å†™ä»»ä½•æ•°æ®æ“ä½œä»£ç å‰ï¼Œå¿…é¡»å…ˆè¯†åˆ«å­—æ®µç®¡ç†ç­–ç•¥ã€‚

#### å­—æ®µåˆ†ç±»ä¾¦æ¢å·¥ä½œ
```bash
# 1. æ‰¾ Model/Entity å®šä¹‰
find . -type f \( -name "*model*" -o -name "*entity*" -o -name "*schema*" \) \
  ! -path "*/node_modules/*" ! -path "*/venv/*" | head -20

# 2. æ‰¾ Migration æ–‡ä»¶ï¼ˆæœ€å¯é ï¼‰
find . -name "*migration*" -o -name "*alembic*" -o -name "*prisma*" | head -10

# 3. æ£€æŸ¥è¡¨ç»“æ„ï¼ˆç›´è¿æ•°æ®åº“æ—¶ï¼‰
# PostgreSQL: \d+ table_name
# MySQL: SHOW CREATE TABLE table_name;
```

#### å­—æ®µç±»å‹è¯†åˆ«æ¸…å•
```
è‡ªåŠ¨ç®¡ç†å­—æ®µï¼ˆæ¡†æ¶/æ•°æ®åº“ç”Ÿæˆï¼Œä¸èƒ½æ‰‹åŠ¨èµ‹å€¼ï¼‰:
â–¡ id (ä¸»é”®): AUTO_INCREMENT / SERIAL / @default(autoincrement())
â–¡ created_at: DEFAULT CURRENT_TIMESTAMP / @default(now())
â–¡ updated_at: ON UPDATE CURRENT_TIMESTAMP / @updatedAt
â–¡ uuid: @default(uuid()) / DEFAULT gen_random_uuid()
â–¡ version: ä¹è§‚é”ç‰ˆæœ¬å·ï¼ˆORMè‡ªåŠ¨ç®¡ç†ï¼‰

æ‰‹åŠ¨èµ‹å€¼å­—æ®µï¼ˆä¸šåŠ¡é€»è¾‘è®¡ç®—/ç”¨æˆ·è¾“å…¥ï¼‰:
â–¡ user_id: å¤–é”®ï¼Œä»ä¸Šä¸‹æ–‡è·å–
â–¡ status: ä¸šåŠ¡çŠ¶æ€ï¼Œæ˜¾å¼æŒ‡å®š
â–¡ name/email: ç”¨æˆ·è¾“å…¥
â–¡ computed_field: ä¸šåŠ¡è®¡ç®—å­—æ®µ

æ¡ä»¶ç®¡ç†å­—æ®µï¼ˆçœ‹åœºæ™¯ï¼‰:
â–¡ deleted_at: è½¯åˆ é™¤ï¼Œç”±åˆ é™¤æ“ä½œèµ‹å€¼
â–¡ last_login_at: ç”±ç™»å½•é€»è¾‘æ›´æ–°
```

#### å®æˆ˜ç¤ºä¾‹ï¼šåˆ›å»ºç”¨æˆ·

**âŒ é”™è¯¯ç¤ºä¾‹**ï¼ˆæ··æ·†è‡ªåŠ¨/æ‰‹åŠ¨å­—æ®µï¼‰:
```python
# åç¤ºä¾‹ï¼šæ‰‹åŠ¨èµ‹å€¼è‡ªåŠ¨ç”Ÿæˆå­—æ®µ
user = User(
    id=123,  # âŒ æ•°æ®åº“è‡ªåŠ¨ç”Ÿæˆï¼Œä¸åº”æ‰‹åŠ¨èµ‹å€¼
    name="Alice",
    email="alice@example.com",
    created_at=datetime.now(),  # âŒ DEFAULT CURRENT_TIMESTAMP å·²è®¾ç½®
    updated_at=datetime.now()   # âŒ è§¦å‘å™¨/ORMè‡ªåŠ¨ç®¡ç†
)
```

**âœ… æ­£ç¡®ç¤ºä¾‹**ï¼ˆåªèµ‹å€¼æ‰‹åŠ¨å­—æ®µï¼‰:
```python
# å¥½ç¤ºä¾‹ï¼šåªä¼ å¿…éœ€çš„æ‰‹åŠ¨å­—æ®µ
user = User(
    name="Alice",          # âœ… æ‰‹åŠ¨èµ‹å€¼
    email="alice@example.com",  # âœ… æ‰‹åŠ¨èµ‹å€¼
    status="active",       # âœ… ä¸šåŠ¡å­—æ®µ
    role_id=3             # âœ… å¤–é”®ï¼Œä»ä¸Šä¸‹æ–‡è·å–
)
# id, created_at, updated_at ç”±æ•°æ®åº“/ORMè‡ªåŠ¨ç”Ÿæˆ
session.add(user)
session.commit()
```

#### éªŒè¯æ–¹æ³•
```python
# æ–¹æ³•1ï¼šæ£€æŸ¥ Model å®šä¹‰
class User(Base):
    __tablename__ = "users"
    id = Column(Integer, primary_key=True, autoincrement=True)  # ğŸ¤– è‡ªåŠ¨
    created_at = Column(DateTime, server_default=func.now())    # ğŸ¤– è‡ªåŠ¨
    updated_at = Column(DateTime, onupdate=func.now())          # ğŸ¤– è‡ªåŠ¨
    name = Column(String(100), nullable=False)                  # âœ‹ æ‰‹åŠ¨
    email = Column(String(255), unique=True)                    # âœ‹ æ‰‹åŠ¨

# æ–¹æ³•2ï¼šæµ‹è¯•æ’å…¥ç©ºå¯¹è±¡
user = User()  # çœ‹å“ªäº›å­—æ®µæŠ¥é”™ = å¿…é¡»æ‰‹åŠ¨èµ‹å€¼
```

### 5. è§„èŒƒåŒ–æ–°å»ºï¼ˆæ— ç°æˆæ—¶ï¼‰

**ç›®å½•ç»“æ„**: `models/`(è¡¨ç»“æ„) â†’ `repositories/`(å•è¡¨æ“ä½œ) â†’ `services/`(ä¸šåŠ¡ç»„åˆ) â†’ `schemas/`(DTO)

**å‘½åè§„èŒƒ**: `get_by_{field}` | `list_{entities}` | `find_by_{condition}` | `create/update/delete_{entity}`

**Repository æ¨¡æ¿**ï¼ˆå¸¦å­—æ®µè¯†åˆ«æ³¨é‡Šï¼‰:
```python
class UserRepository:
    def __init__(self, session: Session):
        self.session = session

    def get_by_id(self, user_id: int) -> User | None:
        """æŸ¥è¯¢ï¼šä¸æ¶‰åŠå­—æ®µç”Ÿæˆ"""
        return self.session.query(User).filter(User.id == user_id).first()

    def create(self, name: str, email: str, role_id: int) -> User:
        """åˆ›å»ºï¼šåªä¼ æ‰‹åŠ¨å­—æ®µï¼Œid/created_atè‡ªåŠ¨ç”Ÿæˆ"""
        user = User(
            name=name,        # âœ‹ æ‰‹åŠ¨
            email=email,      # âœ‹ æ‰‹åŠ¨
            role_id=role_id   # âœ‹ æ‰‹åŠ¨ï¼ˆå¤–é”®ï¼‰
            # id, created_at, updated_at è‡ªåŠ¨ç”Ÿæˆ ğŸ¤–
        )
        self.session.add(user)
        self.session.commit()
        self.session.refresh(user)  # è·å–è‡ªåŠ¨ç”Ÿæˆçš„å€¼
        return user

    def update(self, user_id: int, **kwargs) -> User:
        """æ›´æ–°ï¼šupdated_at è‡ªåŠ¨æ›´æ–°"""
        user = self.get_by_id(user_id)
        if not user:
            raise ValueError(f"User {user_id} not found")

        # åªæ›´æ–°æ‰‹åŠ¨å­—æ®µ
        allowed_fields = {'name', 'email', 'status'}  # ç™½åå•
        for key, value in kwargs.items():
            if key in allowed_fields:
                setattr(user, key, value)

        # updated_at ç”± onupdate è‡ªåŠ¨å¤„ç† ğŸ¤–
        self.session.commit()
        self.session.refresh(user)
        return user

    def list_by_status(self, status: str, limit: int = 100, offset: int = 0) -> list[User]:
        """æŸ¥è¯¢ï¼šåˆ†é¡µæ ‡é…"""
        return self.session.query(User)\
            .filter(User.status == status)\
            .order_by(User.created_at.desc())\
            .limit(limit).offset(offset).all()
```

**åŸåˆ™**:
- å•ä¸€èŒè´£ï¼ˆä¸€ä¸ª Repository ä¸€å¼ è¡¨ï¼‰
- **å­—æ®µç™½åå•**ï¼ˆæ˜ç¡®åŒºåˆ†è‡ªåŠ¨/æ‰‹åŠ¨å­—æ®µï¼‰
- å‚æ•°åŒ–ï¼ˆé¿å…ç¡¬ç¼–ç ï¼‰
- åˆ†é¡µæ ‡é…
- Service å±‚æ§åˆ¶äº‹åŠ¡

### 5. æŸ¥è¯¢ä¼˜åŒ–
| æ•°æ®åº“ | æ¨è | é¿å… |
|-------|-----|------|
| PostgreSQL/MySQL | å‚æ•°åŒ–SQL + ç´¢å¼• | å­—ç¬¦ä¸²æ‹¼æ¥ã€SELECT * |
| MongoDB | Aggregation Pipeline | å®¢æˆ·ç«¯å¾ªç¯å¤„ç† |
| Elasticsearch | Query DSL | å…¨è¡¨æ‰«æåè¿‡æ»¤ |

**æ€§èƒ½æ£€æŸ¥**: ç”¨ç´¢å¼•äº†å— â†’ N+1é—®é¢˜ â†’ åˆ†é¡µäº†å— â†’ éœ€è¦ç¼“å­˜å—

### 6. éªŒè¯
ç»“æœæ­£ç¡®ï¼Ÿæ€§èƒ½è¾¾æ ‡ï¼Ÿéœ€è¦ç¼“å­˜ï¼Ÿæ—¥å¿—æ­£å¸¸ï¼Ÿ

## å…ƒæ•°æ®æ²‰æ·€
å‘ç°çš„ schema å­˜åˆ° `references/schema/`ï¼ŒæŸ¥è¯¢æ–¹æ³•è®°å½•åˆ° `references/queries/existing_queries.yaml`

## NEVER
- ä¸é¢„è®¾æ•°æ®åº“ç±»å‹ï¼Œå…ˆæ¢ç´¢å†å†³ç­–
- ä¸è·³è¿‡ç°æœ‰æ–¹æ³•æœç´¢
- ä¸æ‰§è¡Œ DELETE/DROP ä¸ç¡®è®¤
- ä¸å¿½è§†åˆ†é¡µ
- ä¸ç¡¬ç¼–ç è¿æ¥ä¿¡æ¯
- **ä¸è·³è¿‡è·¨æ•°æ®æºé¢„æ£€ï¼ˆä¼šå¯¼è‡´å¤šæ¬¡è¿”å·¥ï¼‰**
- **ä¸ç”¨å•ä¸€æ•°æ®æºçš„æµ‹è¯•æ•°æ®æµ‹è¯•é›†æˆåŠŸèƒ½ï¼ˆä¼šå‡ºç°è™šå‡æˆåŠŸï¼‰**

---

## å¸¸è§å‘ä¸é¿å‘æŒ‡å—

### å‘ #1: è·¨æ•°æ®æºé›†æˆæœªåšæ•°æ®åŒ¹é…éªŒè¯

**ç—‡çŠ¶**: ä»£ç å†™å¥½äº†ï¼Œæµ‹è¯•ä¸€ç›´ 404 æˆ–è€…è¿”å›ç©ºæ•°æ®

**æ ¹å› **: æ²¡æœ‰éªŒè¯ä¸¤ä¸ªæ•°æ®æºçš„å…³è”é”®æ˜¯å¦æœ‰å®é™…äº¤é›†

**é¿å‘**:
```python
# åœ¨å†™ä»£ç å‰ï¼Œå…ˆè¿è¡Œè¿™ä¸ªéªŒè¯è„šæœ¬
def validate_before_coding():
    # 1. è·å–ä¸»æ•°æ®æºçš„ 100 ä¸ª ID
    mysql_ids = get_mysql_sample_ids(100)

    # 2. åœ¨ MongoDB ä¸­æŸ¥æ‰¾è¿™äº› ID
    mongo_matches = mongodb.find({"url_md5": {"$in": mysql_ids}})

    # 3. è®¡ç®—åŒ¹é…ç‡
    match_rate = len(mongo_matches) / len(mysql_ids)

    if match_rate < 0.3:
        print(f"âŒ æ•°æ®åŒ¹é…ç‡ä»… {match_rate:.1%}ï¼Œä¸å»ºè®®ç»§ç»­")
        print("å»ºè®®: æ£€æŸ¥æ•°æ®åŒæ­¥ã€å­—æ®µæ˜ å°„ã€æ•°æ®æ—¶é—´èŒƒå›´")
        return False

    print(f"âœ… æ•°æ®åŒ¹é…ç‡: {match_rate:.1%}")
    print(f"å¯ç”¨æµ‹è¯• ID: {mongo_matches[:5]}")
    return True
```

### å‘ #2: Settings é…ç½®ä¸å®Œæ•´å¯¼è‡´è¿è¡Œæ—¶é”™è¯¯

**ç—‡çŠ¶**: ä»£ç è¯­æ³•æ­£ç¡®ï¼Œä½†è¿è¡Œæ—¶æŠ¥ `AttributeError: 'Settings' object has no attribute 'XXX'`

**æ ¹å› **: åœ¨ `.env` ä¸­æ·»åŠ äº†é…ç½®ï¼Œä½†å¿˜è®°åœ¨ `settings.py` çš„ Settings ç±»ä¸­æ·»åŠ å¯¹åº”å­—æ®µ

**é¿å‘æ£€æŸ¥æ¸…å•**:
```
â–¡ åœ¨ .env ä¸­æ·»åŠ äº†é…ç½®å˜é‡
â–¡ åœ¨ settings.py çš„ Settings ç±»ä¸­æ·»åŠ äº†å¯¹åº”çš„ Field å®šä¹‰
â–¡ é‡å¯äº†åº”ç”¨ï¼ˆSettings æ˜¯å¯åŠ¨æ—¶åŠ è½½çš„ï¼‰
â–¡ ç”¨ settings.FIELD_NAME æµ‹è¯•æ˜¯å¦èƒ½è®¿é—®
```

### å‘ #3: å­—æ®µåå‡è®¾é”™è¯¯

**ç—‡çŠ¶**: MongoDB æŸ¥è¯¢è¿”å›ç©ºï¼Œä½†æ•°æ®æ˜æ˜å­˜åœ¨

**æ ¹å› **: å‡è®¾å­—æ®µåæ˜¯ `md5_url`ï¼Œå®é™…æ˜¯ `url_md5`

**é¿å‘**:
```python
# æ°¸è¿œå…ˆæŸ¥çœ‹å®é™…æ•°æ®ç»“æ„
def inspect_first_document(collection):
    doc = collection.find_one()
    if doc:
        print("å®é™…å­—æ®µ:", list(doc.keys()))
        for key, value in doc.items():
            print(f"  {key}: {type(value).__name__}")
    return doc
```

### å‘ #4: æµ‹è¯•æ•°æ®é€‰æ‹©é”™è¯¯

**ç—‡çŠ¶**: å•ç‹¬æµ‹è¯• MongoDB å’Œ MySQL éƒ½æˆåŠŸï¼Œä½†é›†æˆæµ‹è¯• 404

**æ ¹å› **: ç”¨çš„æµ‹è¯• ID åªåœ¨ä¸€ä¸ªæ•°æ®æºä¸­å­˜åœ¨

**é¿å‘**:
```python
# å¿…é¡»ç”¨ä¸¤è¾¹éƒ½å­˜åœ¨çš„ ID æµ‹è¯•
test_ids = get_ids_exist_in_both_sources()
```

---

**IMPORTANT**: ä¸€ä¸ªè¢«å¤ç”¨100æ¬¡çš„ Repository æ–¹æ³•ï¼Œæ¯”100ä¸ªä¸€æ¬¡æ€§æŸ¥è¯¢æ›´æœ‰ä»·å€¼ã€‚
**CRITICAL**: è·¨æ•°æ®æºé›†æˆå¿…é¡»å…ˆåšæ•°æ®åŒ¹é…éªŒè¯ï¼Œå¦åˆ™ä¼šæµªè´¹å¤§é‡æ—¶é—´åœ¨è°ƒè¯•ä¸å­˜åœ¨çš„é—®é¢˜ä¸Šã€‚
